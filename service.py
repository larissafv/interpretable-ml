"""Web service exposing interpretability methods through a REST API.

This module provides a small Flask application that wraps the existing
`Orchestrator` class and exposes HTTP endpoints for triggering model
explanations and retrieving generated plot artifacts.

Endpoints
---------
GET /health
    Liveness probe returning a simple JSON payload.

POST /explain
    Accepts JSON body with content already loaded by the client:

    Required fields:
        input_config: object          # Dict with same structure as input.json
        instances: array              # 2D/3D array-like of instances

    Optional fields:
        ground_truth: array           # Array-like of labels (shape compatible with instances)
        instance_idx: int             # Index of the instance to explain (default: 0)

    The service validates input, runs the orchestrator, and returns
    the list of newly generated plot file names available via /plots/<filename>.

GET /plots/<filename>
    Serves static plot images generated by explanation methods. Images
    are written under the directory configured by `common.conf.PLOT_PATH`.

Usage
-----
Run the service locally:
    python -m interpretable-ml.service

Or (from repository root):
    python interpretable-ml/service.py

Example client code is available in `client_example.py`.

Notes
-----
- This file purposefully avoids advanced dependency injection to keep
  the interface lightweight.
- Any additional metadata (execution time, parameters echo) can be added
  later with minimal changes.
"""

from __future__ import annotations

import logging
import os
import tempfile
import time
from pathlib import Path
from typing import Iterator

import h5py
import numpy as np
import pandas as pd
from flask import Flask, Response, jsonify, render_template, request, send_from_directory, session
from werkzeug.datastructures import FileStorage

from common.conf import PLOT_PATH
from orchestrator.orchestrator import Orchestrator
from orchestrator.structs import OrchestratorConfig

# ---------------------------------------------------------------------------
# Logging configuration
# ---------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
logger = logging.getLogger("service")


# ---------------------------------------------------------------------------
# Flask application factory
# ---------------------------------------------------------------------------
app = Flask(__name__)
# Minimal secret key for session-based config storage (override via env var)
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "dev-secret-change-me")


def _safe_listdir_plots() -> set[str]:
    """Return a set with current PNG filenames in the plot directory.

    This helper is used to compute the delta of newly generated artifacts
    after an explanation run so the response payload only returns files
    created during the current request.
    """
    if not PLOT_PATH.exists():  # Lazy create to avoid runtime errors
        PLOT_PATH.mkdir(parents=True, exist_ok=True)
    return {p.name for p in PLOT_PATH.glob("*.png")}


def _cleanup_plot_directory(remove_all: bool = True) -> int:
    """Delete generated plot image files from the plot directory.

    Parameters
    ----------
    remove_all : bool, default True
        If True, remove all PNG files under ``PLOT_PATH``. In the future this
        could support more granular strategies (e.g., only last run).

    Returns
    -------
    int
        Number of files successfully removed.
    """
    if not PLOT_PATH.exists():  # Nothing to do
        return 0
    removed = 0
    try:
        for p in PLOT_PATH.glob("*.png"):
            if not remove_all:
                # Placeholder for potential future filtering logic
                pass
            try:
                p.unlink(missing_ok=True)  # Python 3.8+ safe removal
                removed += 1
            except OSError:
                logger.warning("Failed to delete plot file: %s", p)
    except Exception:  # noqa: BLE001 - broad to ensure cleanup does not break request
        logger.exception("Unexpected error while cleaning plot directory")
    return removed


def _build_orchestrator_config(payload: dict) -> OrchestratorConfig:
    """Construct an `OrchestratorConfig` from request payload.

    Parameters
    ----------
    payload : dict
        Raw JSON dictionary received from the client.

    Returns
    -------
    OrchestratorConfig
        Validated configuration dataclass instance.
    """
    return OrchestratorConfig(
        method_name=payload.get("method_name"),
        variate_labels=payload.get("variate_labels"),
        class_labels=payload.get("class_labels"),
        instances_config=payload.get("instances_config", {}),
        model_config=payload.get("model_config", {}),
        method_config=payload.get("method_config", {}),
    )


def _config_from_payload(obj: dict | None) -> OrchestratorConfig:
    if not isinstance(obj, dict):
        raise ValueError("'input_config' must be an object (dict).")
    return _build_orchestrator_config(obj)


def _instances_from_payload(obj: object) -> np.ndarray:
    """Convert JSON array-like `instances` to numpy array with basic validation."""
    if obj is None:
        raise ValueError("'instances' is required.")
    arr = np.array(obj)
    if arr.size == 0 or arr.ndim == 0:
        raise ValueError("'instances' must be a non-empty array.")
    return arr


def _ground_truth_from_payload(obj: object | None) -> np.ndarray | None:
    """Convert optional `ground_truth` JSON array-like to numpy array."""
    if obj is None:
        return None
    arr = np.array(obj)
    if arr.size == 0:
        return None
    return arr


def _instances_from_hdf5_upload(
    file_storage: FileStorage, dataset_name: str | None = None
) -> np.ndarray:
    """Load instances numpy array from an uploaded HDF5 file.

    Saves to a temporary file for compatibility with h5py and loads the selected dataset.
    """
    if file_storage is None or not getattr(file_storage, "filename", None):
        raise ValueError("'instances_file' is required and must be a valid .hdf5 file.")
    filename = file_storage.filename.lower()
    if not filename.endswith(".hdf5") and not filename.endswith(".h5"):
        raise ValueError("'instances_file' must have extension .hdf5 or .h5")

    with tempfile.NamedTemporaryFile(suffix=".hdf5", delete=False) as tmp:
        tmp_path = tmp.name
        file_storage.save(tmp_path)

    try:
        with h5py.File(tmp_path, "r") as h5:
            if not dataset_name or not isinstance(dataset_name, str) or not dataset_name.strip():
                raise ValueError(
                    (
                        "A 'dataset_name' must be provided to locate the instances dataset "
                        + "inside the HDF5 file."
                    )
                )

            ds_name = dataset_name.strip()
            # 1) Direct root-level lookup
            if ds_name in h5 and isinstance(h5[ds_name], h5py.Dataset):
                data = h5[ds_name][...]
            else:
                # 2) Recursive search by absolute path or basename
                found = None

                def iter_datasets(group: h5py.Group) -> Iterator[h5py.Dataset]:
                    for _k, obj in group.items():
                        if isinstance(obj, h5py.Dataset):
                            yield obj
                        elif isinstance(obj, h5py.Group):
                            yield from iter_datasets(obj)

                for ds in iter_datasets(h5):
                    if ds.name == ds_name or Path(ds.name).name == ds_name:
                        found = ds
                        break

                if found is None:
                    raise ValueError(
                        f"Dataset '{ds_name}' not found in the provided HDF5 file."
                    )
                data = found[...]
    finally:
        try:
            os.remove(tmp_path)
        except OSError:
            pass

    arr = np.array(data)
    if arr.size == 0 or arr.ndim == 0:
        raise ValueError("Loaded 'instances' from HDF5 is empty.")
    return arr


def _ground_truth_from_csv_upload(file_storage: FileStorage | None) -> np.ndarray | None:
    """Load optional ground truth from a CSV upload into a numpy array.

    Returns None if no file provided. Flattens single-column CSVs.
    """
    if file_storage is None or not getattr(file_storage, "filename", None):
        return None
    name = file_storage.filename.lower()
    if not name.endswith(".csv"):
        raise ValueError("'ground_truth_file' must be a .csv file")
    with tempfile.NamedTemporaryFile(suffix=".csv", delete=False) as tmp:
        tmp_path = tmp.name
        file_storage.save(tmp_path)
    try:
        df = pd.read_csv(tmp_path)
    finally:
        try:
            os.remove(tmp_path)
        except OSError:
            pass
    values = df.values.tolist()
    return np.array(values)


@app.get("/health")
def health() -> Response:  # noqa: D401 - Simple health response
    """Return a simple health status JSON."""
    return jsonify({"status": "ok"})


@app.post("/explain")
def explain() -> Response:  # noqa: D401 - Flask route wrapper
    """Trigger an explanation using the orchestrator.

    The request body must follow the schema described in the module level
    docstring. Errors are returned with HTTP 400 (validation) or 500 (runtime).
    """
    start_time = time.time()
    try:
        is_multipart = request.content_type and "multipart/form-data" in request.content_type
        if is_multipart:
            # Gather from multipart form
            input_config_obj = session.get("input_config")
            instances_file = request.files.get("instances_file")
            model_file = request.files.get("model_file")
            ground_truth_file = request.files.get("ground_truth_file")
            instance_idx_raw = request.form.get("instance_idx", 0)
            if input_config_obj is None or instances_file is None or model_file is None:
                return (
                    jsonify(
                        {
                            "status": "error",
                            "message": (
                                "Missing configuration or data. Configure the method first and "
                                + "upload 'instances_file' and 'model_file'."
                            ),
                        }
                    ),
                    400,
                )
            dataset_name = request.form.get("dataset_name") or None
            instances = _instances_from_hdf5_upload(instances_file, dataset_name=dataset_name)
            ground_truth = _ground_truth_from_csv_upload(ground_truth_file)
            payload = {"instance_idx": instance_idx_raw}
            # Persist uploaded model to a temporary file path for Keras
            model_tmp_path = None
            name = model_file.filename.lower()
            if not (name.endswith(".hdf5") or name.endswith(".h5")):
                return (
                    jsonify({
                        "status": "error",
                        "message": "'model_file' must have extension .hdf5 or .h5",
                    }),
                    400,
                )
            with tempfile.NamedTemporaryFile(suffix=".hdf5", delete=False) as tmp_model:
                model_tmp_path = tmp_model.name
                model_file.save(model_tmp_path)
        else:
            # JSON mode (legacy/testing)
            payload = request.get_json(force=True, silent=False)
            if not isinstance(payload, dict):
                return jsonify({"status": "error", "message": "Invalid JSON payload."}), 400

            # Prefer server-stored config provided by the method configuration page
            input_config_obj = session.get("input_config") or payload.get("input_config")
            instances_obj = payload.get("instances")
            ground_truth_obj = payload.get("ground_truth")
            if input_config_obj is None or instances_obj is None:
                return (
                    jsonify(
                        {
                            "status": "error",
                            "message": (
                                "Missing configuration or data. Configure the method first and "
                                + "provide 'instances'."
                            ),
                        }
                    ),
                    400,
                )
            instances = _instances_from_payload(instances_obj)
            ground_truth = _ground_truth_from_payload(ground_truth_obj)

        logger.info(
            "Received explanation request: mode=%s | config=%s | instances shape=%s | gt=%s",
            "multipart" if is_multipart else "json",
            "dict" if isinstance(input_config_obj, dict) else type(input_config_obj).__name__,
            getattr(instances, "shape", None),
            "provided" if ground_truth is not None else "none",
        )

        # Capture current plot artifacts to compute delta after generation
        before_files = _safe_listdir_plots()

        # Validate/convert configuration & data
        config = _config_from_payload(input_config_obj)

        # Resolve and validate instance index
        try:
            instance_idx = int(payload.get("instance_idx", 0))
        except (TypeError, ValueError):
            return jsonify({
                "status": "error",
                "message": "'instance_idx' must be an integer."
            }), 400

        n_instances = int(instances.shape[0]) if getattr(instances, "ndim", 0) >= 1 else 0
        if not (0 <= instance_idx < n_instances):
            msg = "'instance_idx' must be in [0, {lo}] for {n} instances.".format(
                lo=n_instances - 1, n=n_instances
            )
            return jsonify({"status": "error", "message": msg}), 400

        # Create orchestrator and run explanation. Ensure temp model cleanup.
        model_path_to_use = locals().get("model_tmp_path", None)
        try:
            orchestrator = Orchestrator(config, model_path=model_path_to_use)
            # Capture potential return value (e.g., fitness for counterfactual flows)
            result = orchestrator.explain(instances, instance_idx, ground_truth)
        finally:
            if model_path_to_use:
                try:
                    os.remove(model_path_to_use)
                except OSError:
                    pass

        # Compute newly generated plot files
        after_files = _safe_listdir_plots()
        new_files = sorted(after_files - before_files)

        elapsed = round(time.time() - start_time, 3)
        # Persist last results in session for results page rendering
        session["last_plot_files"] = new_files
        session["last_method"] = config.method_name
        session["last_elapsed"] = elapsed

        # Store fitness (if returned) in a printable form. Try to coerce to float
        # for convenient numeric formatting in the UI; otherwise persist a string.
        session["last_fitness"] = None
        session["last_fitness_str"] = None
        if 'result' in locals() and result is not None:
            try:
                # Attempt numeric coercion
                session["last_fitness"] = float(result)
            except Exception:
                # Fall back to string representation
                try:
                    session["last_fitness_str"] = str(result)
                except Exception:
                    session["last_fitness_str"] = None

        response = {
            "status": "success",
            "method": config.method_name,
            "message": "Explanation completed.",
            "plot_files": new_files,
            "elapsed_seconds": elapsed,
            "fitness": (
                session.get("last_fitness")
                if session.get("last_fitness") is not None
                else session.get("last_fitness_str")
            ),
        }
        return jsonify(response)

    except ValueError as ve:  # Configuration / validation errors
        logger.exception("Validation error during explanation")
        return jsonify({"status": "error", "message": str(ve)}), 400
    except Exception as exc:  # noqa: BLE001 - broad catch to surface runtime issues
        logger.exception("Unexpected error during explanation")
        return (
            jsonify({"status": "error", "message": f"Internal server error: {exc}"}),
            500,
        )


@app.post("/config")
def save_config() -> Response:
    """Persist the chosen method configuration into the user session.

    Expects JSON body in either of the following formats:
      - {"input_config": { ... }}
      - { ... }  (direct config object)

    Returns a small acknowledgement JSON with detected method name.
    """
    try:
        payload = request.get_json(force=True, silent=False)
        if not isinstance(payload, dict):
            return jsonify({"status": "error", "message": "Invalid JSON payload."}), 400

        # Accept both wrapper and direct config objects
        cfg_obj = payload.get("input_config") if "input_config" in payload else payload
        cfg = _config_from_payload(cfg_obj)

        session["input_config"] = cfg_obj  # store raw dict
        logger.info("Saved configuration for method=%s into session", cfg.method_name)
        return jsonify({
            "status": "success",
            "message": "Configuration saved.",
            "method": cfg.method_name,
        })
    except ValueError as ve:
        logger.exception("Validation error while saving configuration")
        return jsonify({"status": "error", "message": str(ve)}), 400
    except Exception as exc:  # noqa: BLE001
        logger.exception("Unexpected error while saving configuration")
        return jsonify({"status": "error", "message": f"Internal server error: {exc}"}), 500


@app.get("/config")
def get_config() -> Response:
    """Return the currently stored configuration (for debugging/UI)."""
    cfg = session.get("input_config")
    if not cfg:
        return jsonify({"status": "error", "message": "No configuration set."}), 404
    return jsonify({"status": "success", "input_config": cfg})


@app.get("/plots/<path:filename>")
def get_plot(filename: str) -> Response:  # noqa: D401 - Simple file serving route
    """Serve a generated plot file from the configured plot directory."""
    if not PLOT_PATH.exists():
        return jsonify({"status": "error", "message": "No plots directory found."}), 404
    file_path = PLOT_PATH / filename
    if not file_path.exists():
        return jsonify({"status": "error", "message": "File not found."}), 404
    return send_from_directory(PLOT_PATH, filename, mimetype="image/png")


@app.get("/")
def home() -> str:
    """Render the landing page with available interpretability methods."""
    # If user previously viewed results, perform cleanup of plot artifacts.
    if session.pop("ready_for_plot_cleanup", False):
        removed = _cleanup_plot_directory(remove_all=True)
        logger.info("Cleaned up %d plot file(s) after returning home", removed)
        # Clear session references to old plots
        session.pop("last_plot_files", None)
        session.pop("last_method", None)
        session.pop("last_elapsed", None)
    return render_template("index.html")


@app.get("/methods/lime")
def method_lime() -> str:
    """Render the configuration form for the LIME method."""
    return render_template("method_lime.html")


@app.get("/methods/pfi-local")
def method_pfi_local() -> str:
    """Render the configuration form for the PFILocal method."""
    return render_template("method_pfi_local.html")


@app.get("/methods/counterfactual-explanations")
def method_counterfactual() -> str:
    """Render the configuration form for the Counterfactual Explanations method."""
    return render_template("method_counterfactual.html")


@app.get("/methods/global-surrogate")
def method_global_surrogate() -> str:
    """Render the configuration form for the Global Surrogate method."""
    return render_template("method_global_surrogate.html")


@app.get("/methods/counterfactual-with-pfi")
def method_counterfactual_with_pfi() -> str:
    """Render hybrid configuration form for Counterfactual + PFI Local."""
    return render_template("method_counterfactual_with_pfi.html")


@app.get("/instructions")
def instructions() -> str:
    """Render a short instructions page to guide users through the demo."""
    return render_template("instructions.html")


@app.get("/methods-descriptions")
def methods_descriptions() -> str:
    """Render method descriptions explaining each available technique."""
    return render_template("methods_descriptions.html")


@app.get("/run/setup")
def run_setup() -> str:
    """Render the page to upload instances/model and provide runtime inputs."""
    return render_template("run_setup.html")


@app.get("/results")
def results() -> str:
    """Render a page displaying the most recent explanation plots.

    Uses filenames stored in the session by the last /explain invocation.
    If none are available, shows a friendly message.
    """
    files = session.get("last_plot_files", []) or []
    method = session.get("last_method", "")
    elapsed = session.get("last_elapsed", None)
    fitness = session.get("last_fitness", None)
    fitness_str = session.get("last_fitness_str", None)
    # Mark session to allow plot cleanup when user returns home.
    session["ready_for_plot_cleanup"] = True
    return render_template(
        "results.html",
        plot_files=files,
        method=method,
        elapsed=elapsed,
        fitness=fitness,
        fitness_str=fitness_str,
    )


def create_app() -> Flask:
    """Return the configured Flask application instance.

    Useful for integrating with WSGI servers (gunicorn, uwsgi) or tests.
    """
    return app


if __name__ == "__main__":  # pragma: no cover - manual start block
    # Run development server (safe defaults). Enable debug by setting FLASK_DEBUG=1
    debug_mode = os.environ.get("FLASK_DEBUG", "0") == "1"
    host = os.environ.get("FLASK_HOST", "127.0.0.1")
    port = int(os.environ.get("FLASK_PORT", "5000"))
    app.run(host=host, port=port, debug=debug_mode)
